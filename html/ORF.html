<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Create a Online Random Forest Object</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for ORF"><tr><td>ORF</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Create a Online Random Forest Object</h2>

<h3>Description</h3>

<p>ORF is a class of R6.
You can use it to create a <strong>random forest</strong> via diffrent ways, which supports incremental learning as well as batch learning.
As a matter of fact, the Online Random Forest is made of a list of <code>Online Random Trees</code>.
</p>


<h3>Usage</h3>

<pre>
ORF$new(param, numTrees = 100)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>param</code></td>
<td>
<p>A list which usually has names of <code>minSamples, minGain, numClasses, x.rng, etc.</code>.
More details show in <code>Online Random Tree</code>.</p>
</td></tr>
<tr valign="top"><td><code>numTrees</code></td>
<td>
<p>A nonnegative integer indicates how many ORT trees are going to build.</p>
</td></tr>
</table>


<h3>Format</h3>

<p><code>R6Class</code> object.</p>


<h3>Details</h3>

<p>Online Random Forest was first introduced by <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.150.1671&amp;rep=rep1&amp;type=pdf">Amir Saffari, etc</a>.
After that, <a href="https://github.com/luiarthur/ORFpy">Arthur Lui</a> has implemented the algorithm using Python.
Following the paper's advice and Lui's implemention, I refactor the code via R and R6 package. In additon,
the implemention of ORF in this package support both incremental learning and batch learning by combining with <code>randomForest</code>.
For usage, see details in description of each field or method.
</p>


<h3>Value</h3>

<p>Object of <code>R6Class</code>, Object of <code>Online Random Forest</code>.
</p>


<h3>Fields</h3>


<dl>
<dt><code>numClasses</code></dt><dd><p>A nonnegative integer indicates how many classes when solve a classifation problem. Default 0 for regression. If numClasses &gt; 0, then do classifation.</p>
</dd>
<dt><code>classify</code></dt><dd><p>TRUE for classification and FALSE for Regression, depending on the value of <code>numClasses</code>.</p>
</dd>
<dt><code>forest</code></dt><dd><p>A list of ORT trees. More details show in <code>Online Random Tree</code>.</p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt><code>update(x, y)</code></dt><dd>
<p>When a sample comes in, update all ORT trees in forest with the sample's x variables and y value. <br />
</p>

<ul>
<li><p> x - The x variables of a sample. Note it is an numeric vector other than a scalar.
</p>
</li>
<li><p> y - The y value of a sample.
</p>
</li></ul>

</dd>
<dt><code>generateForest(rf, df.train, y.col)</code></dt><dd>
<p>Generate a list of ORT trees, call function <code>ORT$generateTree()</code> inside.<br />
</p>

<ul>
<li><p> tree.mat - A tree matrix which can be obtained from <code>randomForest::getTree()</code>. Node that it must have a column named <strong>node.ind</strong>. See <strong>Examples</strong>. <br />
</p>
</li>
<li><p> df.train -  The training data frame which has been used to contruct randomForest,
i.e., the <strong>data</strong> argument in <code>randomForest</code> function.
</p>
</li></ul>

</dd>
<dt><code>predict(x)</code></dt><dd>
<p>Predict the corresponding y value of x, using all ORT trees.
</p>

<ul>
<li><p> x - The x variables of a sample. Note it is an numeric vector other than a scalar.
</p>
</li></ul>

</dd>
<dt><code>predicts(X)</code></dt><dd>
<p>Predict the corresponding y value of x, using all ORT trees.
</p>

<ul>
<li><p> X - A matrix or a data frame corresponding to a batch of samples' x variables.
</p>
</li></ul>

</dd>
<dt><code>confusionMatrix(X, y, pretty = FALSE)</code></dt><dd>
<p>Get a confusion matrix about predicted y values and true y values. Only for classification problem.
</p>

<ul>
<li><p> X - A matrix or a data frame corresponding to a batch of samples' x variables.
</p>
</li>
<li><p> y - A vector of y values corresponding to a batch of samples.
</p>
</li>
<li><p> pretty - If TRUE, print a pretty confusion matrix (need <code>gmodels</code> package). Default FALSE.
</p>
</li></ul>

</dd>
<dt><code>meanTreeSize()</code></dt><dd><p>Mean size of ORT trees in the forest.</p>
</dd>
<dt><code>meanNumLeaves()</code></dt><dd><p>Mean leaf nodes numbers of ORT trees in the forest.</p>
</dd>
<dt><code>meanTreeDepth()</code></dt><dd><p>Mean depth of ORT trees in the forest.</p>
</dd>
<dt><code>sdTreeSize()</code></dt><dd><p>Standard deviation for size of ORT trees in the forest.</p>
</dd>
<dt><code>sdTreeSize()</code></dt><dd><p>Standard deviation for leaf nodes numbers of ORT trees in the forest.</p>
</dd>
<dt><code>sdTreeSize()</code></dt><dd><p>Standard deviation for depth of ORT trees in the forest.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Quan Gu
</p>


<h3>Examples</h3>

<pre>
# regression example
if(!require(ggplot2)) install.packages("ggplot2")
data("diamonds", package = "ggplot2")
dat &lt;- as.data.frame(diamonds[sample(1:53000,1000), c(1:6,8:10,7)])
for (col in c("cut","color","clarity")) dat[[col]] &lt;- as.integer(dat[[col]])
x.rng &lt;- data.frame(min = apply(dat[1:9], 2, min),
                    max = apply(dat[1:9], 2, max),
                    row.names = paste0("X", 1:9))
param &lt;- list('minSamples'= 10, 'minGain'= 1, 'maxDepth' = 10, 'x.rng'= x.rng)
ind.gen &lt;- sample(1:1000, 800)
ind.updt &lt;- sample(setdiff(1:1000, ind.gen), 100)
ind.test &lt;- setdiff(setdiff(1:1000, ind.gen), ind.updt)
rf &lt;- randomForest(price ~ ., data = dat[ind.gen, ], maxnodes = 20, ntree = 100)
orf &lt;- ORF$new(param)
orf$generateForest(rf, df.train = dat[ind.gen, ], y.col = "price")
orf$meanTreeSize()
for (i in ind.updt) {
  orf$update(dat[i, 1:9], dat[i, 10])
}
orf$meanTreeSize()

if(!require(Metrics)) install.packages("Metrics")
preds &lt;- orf$predicts(dat[ind.test, 1:9])
Metrics::rmse(preds, dat$price[ind.test])
preds.rf &lt;- predict(rf, newdata = dat[ind.test,])
Metrics::rmse(preds.rf, dat$price[ind.test]) # make progress

# classification example
# Just help yourself, boy !

</pre>


</body></html>
