% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ORTree.R
\docType{data}
\name{ORT}
\alias{ORT}
\title{Create a Online Random Tree Object}
\format{\code{\link{R6Class}} object.}
\usage{
ORT$new(param)
}
\arguments{
\item{param}{A list which usually has names of \code{minSamples, minGain, numClasses, x.rng, etc.}.
More details show in \strong{Fields}.}
}
\value{
Object of \code{\link{R6Class}}, Object of \code{Online Random Tree}.
}
\description{
ORT is a class of R6 and it inherits the \code{\link{Tree}} class.
You can use it to create a \strong{decision tree} via diffrent ways, which supports incremental learning as well as batch learning.
}
\details{
See details in description of each field or method.
}
\section{Fields}{

\describe{
\item{\code{age}}{How many times has the loop go through inside the \code{update()} function.}
\item{\code{minSamples}}{A part of \code{param} indicates the minimal samples in a leaf node. For classification, lower, for regression, higher.}
\item{\code{minGain}}{A part of \code{param} indicates minimal entropy gain when split a node. For classification, lower, for regression, higher.}
\item{\code{numTests}}{A part of \code{param} indicates the number of \code{SuffStats} in tests. Default 10 if not set.}
\item{\code{maxDepth}}{A part of \code{param} indicates max depth of an ORT tree. Default 10 if not set.}
\item{\code{numClasses}}{A nonnegative integer indicates how many classes when solve a classifation problem. Default 0 for regression. If numClasses > 0, then do classifation.}
\item{\code{classValues}}{All diffrent possible values of y if classification. Default NULL if not set.}
\item{\code{x.rng}}{
A data frame which indicates the range of every x variable in training data.
It must be a shape of \code{n*2} which n is the number of x variables, i.e. \code{x.dim}.
And the first collumn must be the minimal values of x and the second as maximum.
You can generate it via \code{OnlineRandomForest::dataRange()} for convenience.
}
\item{\code{...}}{Other fields can be seen in \code{\link{Tree}}.}
}
}

\section{Methods}{

\describe{
\item{\code{findLeaf(x, tree, depth = 0)}}{
Find the leaf node where x is located. Return a list, including node and its depth.
\itemize{
\item x - A sample of x. \cr
\item tree - An ORT tree or node.
}
}
\item{\code{gains(elem)}}{
Compute the entropy gain on all tests of the elem.
\itemize{
\item elem - An \code{Elem} object.
}
}
\item{\code{update(x, y)}}{
When a sample comes in current node, update ORT with the sample's x variables and y value. \cr
\itemize{
\item x - The x variables of a sample. Note it is an numeric vector other than a scalar.
\item y - The y value of a sample.
}
}
\item{\code{generateTree(tree.mat, df.node, node.ind = 1)}}{
Generate a Tree from a tree matrix which just likes the result of \code{randomForest::getTree()}.\cr
\itemize{
\item tree.mat - A tree matrix which can be obtained from \code{randomForest::getTree()}. Node that it must have a column named \strong{node.ind}. See \strong{Examples}. \cr
\item node.ind - The index of the current node in Tree. Default \code{1} for the root node. For most purposes, don't need to change it.
\item df.node - The training data frame which has been used to contruct randomForest, i.e., the \strong{data} argument in \code{\link[randomForest]{randomForest}} function.
Note that all columns in df.node must be \strong{numeric} ors \strong{integer}.
}
}
\item{\code{predict(x)}}{
Predict the corresponding y value of x.
\itemize{
\item x - The x variables of a sample. Note it is an numeric vector other than a scalar.
}
}
\item{\code{draw()}}{Draw the Tree.}
\item{\code{...}}{Other methods can be seen in \code{\link{Tree}}.}
}
}

\examples{
if(!require(randomForest)) install.packages("randomForest")
library(randomForest)

# classifaction example
dat1 <- iris; dat1[,5] <- as.integer(dat1[,5])
rf <- randomForest(factor(Species) ~ ., data = dat1)
treemat1 <- getTree(rf, 1, labelVar=F)
treemat1 <- cbind(treemat1, node.ind = 1:nrow(treemat1))
x.rng1 <- data.frame(min = apply(dat1[1:4], 2, min), 
                     max = apply(dat1[1:4], 2, max), 
                     row.names = paste0("X",1:4)) # or use dataRange(dat1[1:4])
param1 <- list('minSamples'= 5, 'minGain'= 0.1, 'numClasses'= 3, 'x.rng'= x.rng1)
ort1 <- ORT$new(param1)
ort1$generateTree(treemat1, df.node = dat1) # 23ms, 838KB
ort1$draw()
ort1$left$elem$tests[[1]]$statsL
sapply(1:150, function(i) ort1$predict(dat1[i,1:4]))

# first generate, then update
ind.gen <- sample(1:150,50) # for generate ORT
ind.updt <- setdiff(1:150, ind.gen) # for update ORT
rf2 <- randomForest(factor(Species) ~ ., data = dat1[ind.gen,])
treemat2 <- getTree(rf2, 22, labelVar=F)
treemat2 <- cbind(treemat2, node.ind = 1:nrow(treemat2))
ort2 <- ORT$new(param1)
ort2$draw()
ort2$generateTree(treemat2, df.node = dat1[ind.gen,])
ort2$draw()
for(i in ind.updt) {
  ort2$update(dat1[i,1:4], dat1[i,5])
}
ort2$draw()


# regression example
if(!require(ggplot2)) install.packages("ggplot2")
data("diamonds", package = "ggplot2")
dat3 <- as.data.frame(diamonds[sample(1:53000,1000), c(1:6,8:10,7)])
for (col in c("cut","color","clarity")) dat3[[col]] <- as.integer(dat3[[col]]) # Don't forget !
x.rng3 <- data.frame(min = apply(dat3[1:9], 2, min),
                     max = apply(dat3[1:9], 2, max),
                     row.names = paste0("X", 1:9))
param3 <- list('minSamples'= 10, 'minGain'= 1, 'maxDepth' = 10, 'x.rng'= x.rng3)
ind.gen3 <- sample(1:1000,500)
ind.updt3 <- setdiff(1:1000, ind.gen3)
rf3 <- randomForest(price ~ ., data = dat3[ind.gen3,], maxnodes = 20)
treemat3 <- getTree(rf3, 33, labelVar = F)
treemat3 <- cbind(treemat3, node.ind = 1:nrow(treemat3))

ort3 <- ORT$new(param3)
ort3$generateTree(treemat3, df.node = dat3[ind.gen3,])
ort3$size()
for (i in ind.updt3) {
  ort3$update(dat3[i,1:9], dat3[i,10])
}
ort3$size()


}
\author{
Quan Gu
}
\keyword{datasets}
